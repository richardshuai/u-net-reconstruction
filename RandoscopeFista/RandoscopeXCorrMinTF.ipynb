{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from miniscope_utils_tf import *\n",
    "#import utils as krist\n",
    "import scipy.misc as sc\n",
    "from skimage.transform import resize as imresize\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "from IPython import display\n",
    "import scipy.ndimage as ndim\n",
    "import scipy.misc as misc\n",
    "from scipy import signal\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.animation as animation\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import time\n",
    "from itertools import permutations\n",
    "from itertools import combinations\n",
    "import matplotlib.animation as animation\n",
    "#import copy\n",
    "#from bridson import poisson_disc_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = '/gpu:0'\n",
    "#print(tf.test.is_gpu_available())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model and loss\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, ):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.samples = (768,768)   #Grid for PSF simulation\n",
    "\n",
    "        # min and max lenslet focal lengths in mm\n",
    "        self.fmin = 6.\n",
    "        self.fmax = 20.\n",
    "        self.ior = 1.56\n",
    "        self.lam=510e-6\n",
    "        # Min and max lenslet radii\n",
    "        self.Rmin = self.fmin*(self.ior-1.)\n",
    "        self.Rmax = self.fmax*(self.ior-1.)\n",
    "\n",
    "        # Convert to curvatures\n",
    "        self.cmin = 1/self.Rmax\n",
    "        self.cmax = 1/self.Rmin\n",
    "        self.xgrng = np.array((-1.8, 1.8)).astype('float32')    #Range, in mm, of grid of the whole plane (not just grin)\n",
    "        self.ygrng = np.array((-1.8, 1.8)).astype('float32')\n",
    "\n",
    "        self.t = 10.    #Distance to sensor from mask in mm\n",
    "\n",
    "        #Compute depth range of virtual image that mask sees (this is assuming an objective is doing some magnification)\n",
    "\n",
    "        self.zmin_virtual = 1./(1./self.t - 1./self.fmin)\n",
    "        self.zmax_virtual = 1./(1./self.t - 1./self.fmax)\n",
    "        self.CA = .9; #semi clear aperature of GRIN\n",
    "        self.mean_lenslet_CA = .2 #average lenslest semi clear aperture in mm. \n",
    "            \n",
    "        #Getting number of lenslets and z planes needed as well as defocus list\n",
    "        self.ps = (self.xgrng[1] - self.xgrng[0])/self.samples[0]\n",
    "        self.Nlenslets=np.int(np.floor((self.CA**2)/(self.mean_lenslet_CA**2)))\n",
    "        self.Nz = np.ceil(np.sqrt(self.Nlenslets*2)).astype('int') #number of Zplanes \n",
    "        self.defocus_list = 1./(np.linspace(1/self.zmin_virtual, 1./self.zmax_virtual, self.Nz)) #mm or dioptres\n",
    "        self.lenslet_offset=0.\n",
    "        #initializing the x and y positions\n",
    "        [xpos,ypos, rlist]=poissonsampling_circular(self)\n",
    "        \n",
    "        self.rlist = tf.constant(rlist, dtype = tf.float32)\n",
    "        self.xpos = tfe.Variable(xpos, name='xpos', dtype = tf.float32)\n",
    "        self.ypos = tfe.Variable(ypos, name='ypos', dtype = tf.float32)\n",
    "        \n",
    "        #parameters for making the lenslet surface\n",
    "        self.yg = tf.constant(np.linspace(self.ygrng[0], self.ygrng[1], self.samples[0]),dtype=tf.float32)\n",
    "        self.xg=tf.constant(np.linspace(self.xgrng[0], self.xgrng[1], self.samples[1]),dtype=tf.float32)\n",
    "        self.px=tf.constant(self.xg[1] - self.xg[0],tf.float32)\n",
    "        self.py=tf.constant(self.yg[1] - self.yg[0],tf.float32)\n",
    "        self.xgm, self.ygm = tf.meshgrid(self.xg,self.yg)\n",
    "\n",
    "        #PSF generation parameters\n",
    "        self.lam=tf.constant(510.*10.**(-6.),dtype=tf.float32)\n",
    "        self.k = np.pi*2./self.lam\n",
    "        \n",
    "        fx = tf.constant(np.linspace(-1./(2.*self.ps),1./(2.*self.ps),self.samples[1]),dtype=tf.float32)\n",
    "        fy = tf.constant(np.linspace(-1./(2.*self.ps),1./(2.*self.ps),self.samples[0]),dtype=tf.float32)\n",
    "        self.Fx,self.Fy = tf.meshgrid(fx,fy)\n",
    "        self.field_list = tf.constant(np.array((0., 0.)).astype('float32'))\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        T,aper=make_lenslet_tf(self) #offset added\n",
    "        # Get psf stack\n",
    "        zstack = []\n",
    "        for defocus in self.defocus_list:\n",
    "            zstack.append(gen_psf_ag_tf(T,self,defocus,'angle',0., prop_pad = 0.5))\n",
    "        \n",
    "        #Padding for fft\n",
    "        psf_pad=[]\n",
    "        Rmat = np.zeros((self.Nz,self.Nz))\n",
    "\n",
    "        for z1 in range(self.Nz):\n",
    "            psf_pad.append(pad_frac_tf(zstack[z1],1)) #how much to pad? \n",
    "\n",
    "        psf_spect=[]\n",
    "        \n",
    "        #Getting spectrum\n",
    "\n",
    "        for z1 in range(self.Nz):\n",
    "            psf_spect.append(tf.fft2d(tf.complex(psf_pad[z1],tf.constant(0.,dtype = tf.float32))))\n",
    "\n",
    "        normsize=tf.to_float(tf.shape(psf_spect)[0]*tf.shape(psf_spect)[1])\n",
    "        \n",
    "        Rmat_tf=[]\n",
    "        #calculating Xcorr\n",
    "\n",
    "        for z1 in range(self.Nz):\n",
    "            for z2 in range(self.Nz): \n",
    "                Fcorr = tf.conj(psf_spect[z1])*psf_spect[z2]\n",
    "                Rmat_tf.append(tf.reduce_sum(tf.abs(Fcorr)**2)/normsize)\n",
    "\n",
    "        #Rmat=tf.reshape(Rmat_tf,(self.Nz,self.Nz))\n",
    "            \n",
    "        return Rmat_tf #note this returns int data type!! vector not matrix. This is also my loss!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances(model, x,y):\n",
    "    dist = []\n",
    "    dist_bool = []\n",
    "    things = np.arange(model.Nlenslets)\n",
    "    test_perm = list(permutations(things, 2))\n",
    "\n",
    "    for i in range(0, len(test_perm)):\n",
    "        dist_i = tf.sqrt(tf.square(x[test_perm[i][0]]-x[test_perm[i][1]])+tf.square(y[test_perm[i][0]]-y[test_perm[i][1]]))\n",
    "        dist.append(dist_i)\n",
    "        dist_bool.append(dist_i>1.0*model.mean_lenslet_CA)\n",
    "        \n",
    "    return dist, dist_bool, test_perm\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#with tf.device(\"/gpu:0\"):\n",
    "#    zstack=model(0)\n",
    "#end = time.time()\n",
    "#print(end - start)\n",
    "#with tf.device(\"/cpu:0\"):\n",
    "model = Model()\n",
    "Rmat=model(0)\n",
    "R_init = Rmat\n",
    "Tinit,_=make_lenslet_tf(model)\n",
    "xinit = model.xpos\n",
    "yinit = model.ypos\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(Tinit.numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tf.reshape(R_init,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have tf do everything for us\n",
    "def loss (model):\n",
    "    return tf.reduce_sum(tf.square(model(0)))\n",
    "\n",
    "def gradient (model, myloss):\n",
    "    with tf.GradientTape() as tape:\n",
    "        lossvalue=myloss(model)\n",
    "        return tape.gradient(lossvalue, model.variables),lossvalue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain_distances(model, new_xpos, new_ypos, grads):\n",
    "    test_dist, test_dist_bool, perm = distances(model, new_xpos, new_ypos)\n",
    "    grads = np.ones((2,model.Nlenslets))\n",
    "    for i in range(0,len(perm)):\n",
    "        if test_dist_bool[i].numpy() == False:\n",
    "            index = perm[i][0]\n",
    "            grads[0,index] = 0\n",
    "            grads[1,index] = 0\n",
    "    return grads, test_dist, test_dist_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_grad, test_dist, test_dist_bool = constrain_distances(model, new_xpos, new_ypos, grad) # apply constraint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "step_size = 1000\n",
    "ims=[]\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=step_size)\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "losslist=[]\n",
    "for i in range(10):\n",
    "    grad,lossvalue=gradient(model,loss)\n",
    "\n",
    "    new_xpos = model.xpos - step_size*grad[0]\n",
    "    new_ypos = model.xpos - step_size*grad[1] \n",
    "\n",
    "    new_grad, test_dist, test_dist_bool = constrain_distances(model, new_xpos, new_ypos, grad) # apply constraint \n",
    "\n",
    "    grad[0] = grad[0]*new_grad[0,:]\n",
    "    grad[1] = grad[1]*new_grad[1,:]    # update the gradient\n",
    "\n",
    "    optimizer.apply_gradients(zip(grad,model.variables),global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "\n",
    "    losslist.append(lossvalue)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.cla()\n",
    "    im=plt.plot(model.xpos.numpy(),model.ypos.numpy(),'o')\n",
    "    plt.axis('equal')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.cla()\n",
    "    plt.plot(losslist)\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    ims.append([im])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,aper=make_lenslet_tf(model)\n",
    "R=model(0)\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(T.numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tf.reshape(R,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "def update_line(num, data, line):\n",
    "    line.set_data(data[..., :num])\n",
    "    return line,\n",
    "\n",
    "# Set up formatting for the movie files\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "\n",
    "\n",
    "fig1 = plt.figure()\n",
    "\n",
    "data = np.random.rand(2, 25)\n",
    "l, = plt.plot([], [], 'r-')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('x')\n",
    "plt.title('test')\n",
    "line_ani = animation.FuncAnimation(fig1, update_line, 25, fargs=(data, l),\n",
    "                                   interval=50, blit=True)\n",
    "line_ani.save('lines.mp4', writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zstack = []\n",
    "for defocus in model.defocus_list:\n",
    "    zstack.append(gen_psf_ag_tf(Tinit,model,defocus,'angle',0., prop_pad = 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(zstack[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R=model(0)\n",
    "plt.imshow(tf.reshape(R,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model()\n",
    "Rmat2=model2(0)\n",
    "plt.imshow(tf.reshape(Rmat2,(7,7)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch((model.xpos,model.ypos))\n",
    "        Rmat=model(0) \n",
    "    for z in range(model.Nz**2)\n",
    "    der = t.gradient(Rmat,(model.xpos,model.ypos))\n",
    "#    dery = t.gradient(Rmat,model.ypos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        model = Model()\n",
    "        with tf.GradientTape() as t:\n",
    "            t.watch(model.xpos)\n",
    "            Rmat=model(0) \n",
    "        derx = t.gradient(Rmat,model.xpos)\n",
    "        dery = t.gradient(Rmat,model.ypos)\n",
    "\n",
    "    \n",
    "    theta=theta+(J_f'*J_f)^(-1)*J_f'*residual;\n",
    "    i\n",
    "    sum(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rmat = np.zeros((model.Nz,model.Nz))\n",
    "start = time.time()\n",
    "Rmat_tf=[]\n",
    "psf_pad=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_pad.append(pad_frac_tf(zstack[z1],1)) #how much to pad? \n",
    "    \n",
    "psf_spect=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_spect.append(tf.fft2d(tf.complex(psf_pad[z1],tf.constant(0.,dtype = tf.float32))))\n",
    "\n",
    "normsize=tf.to_float(tf.shape(psf_spect)[0]*tf.shape(psf_spect)[1])\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    for z2 in range( model.Nz): \n",
    "        Fcorr = tf.conj(psf_spect[z1])*psf_spect[z2]\n",
    "        Rmat_tf.append(tf.reduce_sum(tf.abs(Fcorr)**2)/normsize)\n",
    "\n",
    "Rmat=tf.reshape(Rmat_tf,(7,7))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Rmat = np.zeros((model.Nz,model.Nz))\n",
    "#Rmat_tf=[]\n",
    "psf_pad=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_pad.append(pad_frac_tf(zstack[z1],1)) #how much to pad? \n",
    "    \n",
    "psf_spect=[]\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    psf_spect.append(tf.fft2d(tf.complex(psf_pad[z1],tf.constant(0.,dtype = tf.float32))))\n",
    "\n",
    "normsize=tf.to_float(tf.shape(psf_spect)[0]*tf.shape(psf_spect)[1])\n",
    "\n",
    "for z1 in range(model.Nz):\n",
    "    for z2 in range( model.Nz): \n",
    "        Fcorr = tf.conj(psf_spect[z1])*psf_spect[z2]\n",
    "        #Rmat_tf.append(tf.reduce_sum(tf.abs(Fcorr)**2)/normsize)\n",
    "        Rmat[z1,z2] = tf.reduce_sum(tf.abs(Fcorr)**2)/normsize\n",
    "\n",
    "Rmat = tf.transpose(Rmat)*(Rmat==0) + Rmat \n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1 = np.fft.fftfreq(30*30, d=1./30).reshape(30, 30)\n",
    "freqs2 = np.fft.fftfreq(30*30, d=1./40).reshape(30, 30)\n",
    "\n",
    "freqp1=np.pad(freqs1, ((30,30),(30,30)), 'constant', constant_values=(0,0))\n",
    "freqp2=np.pad(freqs2, ((30,30),(30,30)), 'constant', constant_values=(0,0))\n",
    "\n",
    "#zstack1p= pad_frac_tf(freqs1,1) #how much to pad with?\n",
    "#zstack2p= pad_frac_tf(freqs2,1)\n",
    "\n",
    "psf_spect1 = tf.fft2d(tf.complex(freqp1,tf.constant(0.,dtype = tf.float64)))\n",
    "psf_spect2 = tf.fft2d(tf.complex(freqp2,tf.constant(0.,dtype = tf.float64)))\n",
    "\n",
    "Fcorr = tf.conj(psf_spect1)*psf_spect2\n",
    "Rmat = tf.reduce_sum(tf.abs(Fcorr)**2)/(tf.to_float(tf.shape(freqp1)[0]*tf.shape(freqp1)[1]))\n",
    "Rmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcorr=signal.correlate2d(freqs1,freqs2)\n",
    "xcorr_sum=np.sum(np.abs(xcorr)**2)\n",
    "xcorr_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fcorrinv=np.fft.ifft2(Fcorr)\n",
    "s=np.sum(np.abs(Fcorrinv)**2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_spect = np.fft.fft2(zstack[0],)\n",
    "Rmat = np.zeros((model.Nz,model.Nz))\n",
    "for z1 in range(Nz):\n",
    "    for z2 in np.r_[z1:Nz]:\n",
    "      \n",
    "        Fcorr = np.conj(psf_spect[z1])*psf_spect[z2]\n",
    "        Rmat[z1,z2] = np.sum(np.abs(Fcorr)**2)\n",
    "        \n",
    "Rmat = np.transpose(Rmat)*(Rmat==0) + Rmat\n",
    "plt.imshow(Rmat,vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.fft.fftfreq(9, d=1./9).reshape(3, 3)\n",
    "np.fft.fft2(freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, targets):\n",
    "    error = model(inputs) - targets\n",
    "    return tf.reduce_sum(tf.square(error))\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, [model.Rlist])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
