{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (11000, 648, 486, 1)\n",
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import io\n",
    "import json\n",
    "from os import path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "record_dir = path.join('..', 'data', '2d_data', 'tf_records', 'zebrafish_and_beads', 'sims')\n",
    "dataset_files = glob.glob(path.join(record_dir, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = path.join('..', 'models', '2d_models', 'zebrafish_and_beads', 'zebrafish_and_beads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifted + scaled tanh activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batchnorm epsilon\n",
    "BN_EPS = 1e-4\n",
    "\n",
    "class ConvBnRelu2d(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=(3, 3), padding='same'):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        self.conv = layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', use_bias=False)\n",
    "        self.bn = layers.BatchNormalization(epsilon=BN_EPS)\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class TanhScale(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(TanhScale, self).__init__()\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = K.tanh(x)\n",
    "        x = (x + 1) * 0.5\n",
    "        return x * m\n",
    "\n",
    "class StackEncoder(layers.Layer):\n",
    "    def __init__(self, y_channels, kernel_size=3):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.encode = keras.Sequential([\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same'),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same')\n",
    "        ])\n",
    "        self.max_pool = layers.MaxPool2D(pool_size=2, strides=2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encode(x)\n",
    "        x_small = self.max_pool(x)\n",
    "        return x, x_small\n",
    "\n",
    "\n",
    "class StackDecoder(layers.Layer):\n",
    "    def __init__(self, y_channels, kernel_size=3):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        \n",
    "        self.decode = keras.Sequential([\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same'),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same'),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same'),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def call(self, x, down_tensor):\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        \n",
    "        # Calculate cropping for down_tensor to concatenate with x\n",
    "        _, h2, w2, _ = down_tensor.shape\n",
    "        _, h1, w1, _ = x.shape\n",
    "        h_diff, w_diff = h2 - h1, w2 - w1\n",
    "        \n",
    "        cropping = ((int(np.ceil(h_diff / 2)), int(np.floor(h_diff / 2))),\n",
    "                    (int(np.ceil(w_diff / 2)), int(np.floor(w_diff / 2))))\n",
    "        down_tensor = layers.Cropping2D(cropping=cropping)(down_tensor)        \n",
    "        x = layers.concatenate([x, down_tensor], axis=3)\n",
    "        x = self.decode(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_2d(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(UNet_2d, self).__init__()\n",
    "\n",
    "        self.down1 = StackEncoder(24, kernel_size=3) # 256\n",
    "        self.down2 = StackEncoder(64, kernel_size=3)  # 128\n",
    "        self.down3 = StackEncoder(128, kernel_size=3)  # 64\n",
    "        self.down4 = StackEncoder(256, kernel_size=3)  # 32\n",
    "        self.down5 = StackEncoder(512, kernel_size=3)  # 16\n",
    "        \n",
    "\n",
    "        self.up5 = StackDecoder(256, kernel_size=3)  # 32\n",
    "        self.up4 = StackDecoder(128, kernel_size=3)  # 64\n",
    "        self.up3 = StackDecoder(64, kernel_size=3)  # 128\n",
    "        self.up2 = StackDecoder(24, kernel_size=3)  # 256\n",
    "        self.up1 = StackDecoder(24, kernel_size=3)  # 512\n",
    "        self.classify = layers.Conv2D(filters=1, kernel_size=1, use_bias=True)\n",
    "        \n",
    "        self.center = ConvBnRelu2d(512, kernel_size=3, padding='same')\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        out = x;\n",
    "        down1_tensor, out = self.down1(out)\n",
    "        down2_tensor, out = self.down2(out)\n",
    "        down3_tensor, out = self.down3(out)\n",
    "        down4_tensor, out = self.down4(out)\n",
    "        down5_tensor, out = self.down5(out)\n",
    "\n",
    "        out = self.center(out)\n",
    "        \n",
    "        out = self.up5(out, down5_tensor)\n",
    "        out = self.up4(out, down4_tensor)\n",
    "        out = self.up3(out, down3_tensor)\n",
    "        out = self.up2(out, down2_tensor)\n",
    "        out = self.up1(out, down1_tensor)\n",
    "\n",
    "        out = self.classify(out)\n",
    "        out = tf.squeeze(out, axis=3)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         out = self.activation_fn(out)\n",
    "#         self.activation_fn = TanhScale()\n",
    "#       self.bn = layers.BatchNormalization(epsilon=BN_EPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "#     eps = 1e-1\n",
    "    feature_description = {\n",
    "        'plane': tf.io.FixedLenFeature(obj_dims, tf.float32),\n",
    "        'sim': tf.io.FixedLenFeature(obj_dims, tf.float32)\n",
    "    }\n",
    "    # Parse the input tf.Example proto using the dictionary above.\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    plane = example['plane']\n",
    "    plane = tf.cast(plane, tf.float16)\n",
    "    plane = plane[4:644, 3:483] # Crop to target image size\n",
    "    plane_max = tf.reduce_max(plane)\n",
    "    plane_min = tf.reduce_min(plane)\n",
    "    plane = (plane - plane_min) / (plane_max - plane_min)\n",
    "\n",
    "    sim = example['sim']\n",
    "    sim = tf.cast(sim, tf.float16)\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)\n",
    "    sim = sim[..., np.newaxis] # Expand to channel dimension\n",
    "    \n",
    "    return sim, plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(filenames, train_length, val_length, batch_size):\n",
    "    \"\"\"\n",
    "    Takes in string array of filenames for TFRecord files containing samples.\n",
    "    Returns: train dataset of train_length, val dataset of val_length\n",
    "    \"\"\"\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "#     raw_dataset = tf.data.TFRecordDataset(filenames=filenames)\n",
    "\n",
    "    raw_train_dataset = tf.data.TFRecordDataset(filenames[:train_length])\n",
    "    raw_val_dataset = tf.data.TFRecordDataset(filenames[train_length:train_length + val_length])\n",
    "    \n",
    "    train_dataset = raw_train_dataset.map(_parse_function)\n",
    "    train_dataset = train_dataset.shuffle(256)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    \n",
    "    \n",
    "    val_dataset = raw_val_dataset.map(_parse_function)\n",
    "    val_dataset = val_dataset.shuffle(256)\n",
    "    \n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "#     loss = K.sqrt(loss)\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "    \n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "import datetime\n",
    "log_dir=os.path.join('logs_2d', 'fit') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=1000000)\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "plot_image_tensorboard_cb = keras.callbacks.LambdaCallback(on_epoch_end=plot_image_tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_2d()\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "# model.compile(optimizer=adam, loss=scaled_mse_loss, metrics=['mean_squared_error'])\n",
    "model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "model.build(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LENGTH = len(dataset_files)\n",
    "TRAIN_LENGTH = int(DATASET_LENGTH * 0.8)\n",
    "VAL_LENGTH = DATASET_LENGTH - TRAIN_LENGTH \n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "train_dataset, val_dataset = create_datasets(filenames=dataset_files, train_length=TRAIN_LENGTH, \n",
    "                                  val_length=VAL_LENGTH, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample = next(iter(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          callbacks=[plot_image_tensorboard_cb, tensorboard_callback], validation_data=val_dataset, validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(model_weights_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_2d()\n",
    "model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((VAL_LENGTH, 640, 480))\n",
    "ground_truths = np.zeros((VAL_LENGTH, 640, 480))\n",
    "sims = np.zeros((VAL_LENGTH, 648, 486))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in val_dataset:\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "\n",
    "assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / VAL_LENGTH, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * VAL_LENGTH))\n",
    "rows, columns = VAL_LENGTH, 2\n",
    "for i in range(VAL_LENGTH):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(preds[i])\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig('N_11000_epochs_80.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
