{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.model import UNet_2d\n",
    "\n",
    "\n",
    "import io\n",
    "import json\n",
    "from os import path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = 'model-9.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "record_dir = path.join('..', 'data', model_description)\n",
    "train_dataset_files = glob.glob(path.join(record_dir, 'train', '*'))\n",
    "val_dataset_files = glob.glob(path.join(record_dir, 'validation', '*'))\n",
    "\n",
    "\n",
    "# Paths for saving/loading model weights, predictions\n",
    "base_path = path.join('..', 'models', model_description)\n",
    "model_weights_path = path.join(base_path, model_description)\n",
    "image_path = path.join(base_path, 'prediction-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../models/model-9.2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-87139a59be62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../models/model-9.2'"
     ]
    }
   ],
   "source": [
    "os.mkdir(base_path)\n",
    "os.mkdir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(train_dataset_files)\n",
    "VAL_LENGTH = len(val_dataset_files)\n",
    "input_shape = (TRAIN_LENGTH+VAL_LENGTH, 648, 486, 1)\n",
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "photon_counts = tf.constant([100., 1000., 10000.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'plane': tf.io.FixedLenFeature(obj_dims, tf.float32),\n",
    "        'sim': tf.io.FixedLenFeature(obj_dims, tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    \n",
    "    plane = example['plane']\n",
    "#     plane = tf.cast(plane, tf.float16)\n",
    "#     plane = plane[4:644, 3:483] # Crop to target image size\n",
    "    plane = plane[4:644, 19:467]\n",
    "    plane_max = tf.reduce_max(plane)\n",
    "    plane_min = tf.reduce_min(plane)\n",
    "    plane = (plane - plane_min) / (plane_max - plane_min)  # Normalize values to [0, 1]\n",
    "\n",
    "    sim = example['sim']\n",
    "#     sim = tf.cast(sim, tf.float16)\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)  # Normalize values to [0, 1]\n",
    "    \n",
    "    # Adding Poisson noise to simulated measurements\n",
    "    photon_idx = tf.random.uniform(shape=(), minval=0, maxval=3, dtype=tf.int32)\n",
    "    photon_count = tf.gather(photon_counts, photon_idx)\n",
    "    sim = tf.squeeze(tf.random.poisson([1], sim * photon_count)) / photon_count\n",
    "    \n",
    "    # Renormalize values to [0, 1]\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)\n",
    "    \n",
    "    # Adding Gaussian noise to simulated measurements\n",
    "    a = tf.random.uniform((), 0.0063, 0.0063*4)\n",
    "    b = tf.random.uniform((), 0.06, 0.1)\n",
    "    noise = tf.random.normal(sim.shape, mean=b, stddev=a)\n",
    "    sim = sim + noise\n",
    "\n",
    "    # Renormalize values to [0, 1]\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)\n",
    "    \n",
    "    # Expand to channel dimension\n",
    "    sim = sim[..., tf.newaxis] \n",
    "    \n",
    "    return sim, plane\n",
    "\n",
    "def create_dataset(filenames, batch_size):\n",
    "    \"\"\"\n",
    "    Takes in string array of filenames for TFRecord files containing samples.\n",
    "    Returns: TFRecordDataset with given batch size\n",
    "    \"\"\"\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    \n",
    "    dataset = raw_dataset.map(_parse_function)\n",
    "    dataset = dataset.shuffle(256)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "STEPS_PER_EPOCH = int(np.ceil(TRAIN_LENGTH / BATCH_SIZE))\n",
    "VAL_STEPS = int(np.ceil(VAL_LENGTH / BATCH_SIZE))\n",
    "\n",
    "train_dataset = create_dataset(train_dataset_files, BATCH_SIZE)\n",
    "val_dataset = create_dataset(val_dataset_files, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "\n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "#     loss = K.sqrt(loss)\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "    \n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "import datetime\n",
    "log_dir=os.path.join('logs', model_description + '-fit') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=1000000)\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "plot_image_tensorboard_cb = keras.callbacks.LambdaCallback(on_epoch_end=plot_image_tensorboard)\n",
    "\n",
    "# Save model after epochs\n",
    "checkpoint_cb = ModelCheckpoint(model_weights_path + '.e{epoch:03d}', monitor='val_loss', verbose=0, \n",
    "                             save_best_only=False, save_weights_only=True, mode='auto', \n",
    "                                save_freq=10*STEPS_PER_EPOCH)\n",
    "checkpoint_best_cb = ModelCheckpoint(model_weights_path + '.best', monitor='val_loss', verbose=0,\n",
    "                                    save_best_only=True, save_weights_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "    y_true = y_true[..., np.newaxis]\n",
    "    y_pred = y_pred[..., np.newaxis]\n",
    "    \n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u_net_2d_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "stack_encoder_6 (StackEncode multiple                  5592      \n",
      "_________________________________________________________________\n",
      "stack_encoder_7 (StackEncode multiple                  51200     \n",
      "_________________________________________________________________\n",
      "stack_encoder_8 (StackEncode multiple                  222208    \n",
      "_________________________________________________________________\n",
      "stack_encoder_9 (StackEncode multiple                  886784    \n",
      "_________________________________________________________________\n",
      "stack_encoder_10 (StackEncod multiple                  3543040   \n",
      "_________________________________________________________________\n",
      "stack_encoder_11 (StackEncod multiple                  14163968  \n",
      "_________________________________________________________________\n",
      "conv_bn_relu2d_43 (ConvBnRel multiple                  9441280   \n",
      "_________________________________________________________________\n",
      "stack_decoder_6 (StackDecode multiple                  14161920  \n",
      "_________________________________________________________________\n",
      "stack_decoder_7 (StackDecode multiple                  3542016   \n",
      "_________________________________________________________________\n",
      "stack_decoder_8 (StackDecode multiple                  886272    \n",
      "_________________________________________________________________\n",
      "stack_decoder_9 (StackDecode multiple                  221952    \n",
      "_________________________________________________________________\n",
      "stack_decoder_10 (StackDecod multiple                  38304     \n",
      "_________________________________________________________________\n",
      "stack_decoder_11 (StackDecod multiple                  21024     \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           multiple                  25        \n",
      "=================================================================\n",
      "Total params: 47,185,585\n",
      "Trainable params: 47,169,457\n",
      "Non-trainable params: 16,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = UNet_2d()\n",
    "initial_learning_rate = 1e-4\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "#                                                             decay_steps=STEPS_PER_EPOCH*40,\n",
    "#                                                             decay_rate=0.5,\n",
    "#                                                             staircase=False)\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=adam, loss=SSIMLoss, metrics=SSIMLoss)\n",
    "# model.compile(optimizer=adam, loss=tf.keras.losses.MeanAbsoluteError(), metrics=[tf.keras.losses.MeanAbsoluteError()])\n",
    "model.build(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample = next(iter(val_dataset)) # Used for logging and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      " 53/625 [=>............................] - ETA: 6:57 - loss: 0.9769 - SSIMLoss: 0.9769"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          callbacks=[plot_image_tensorboard_cb, tensorboard_callback, checkpoint_cb, checkpoint_best_cb], \n",
    "          validation_data=val_dataset, validation_steps=VAL_STEPS)\n",
    "\n",
    "model.save_weights(model_weights_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Visualization, Timing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DISPLAY = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_2d()\n",
    "epoch = 'best'\n",
    "model.load_weights(model_weights_path + '.{}'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((NUM_DISPLAY, 640, 448))\n",
    "ground_truths = np.zeros((NUM_DISPLAY, 640, 448))\n",
    "sims = np.zeros((NUM_DISPLAY, 648, 486))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in train_dataset.unbatch():\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "    if i == NUM_DISPLAY:\n",
    "        break\n",
    "        \n",
    "# assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / VAL_LENGTH, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * NUM_DISPLAY))\n",
    "rows, columns = NUM_DISPLAY, 2\n",
    "for i in range(NUM_DISPLAY):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(preds[i])\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig(path.join(image_path, 'train_{}.pdf'.format(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in val_dataset.unbatch():\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "    if i == NUM_DISPLAY:\n",
    "        break\n",
    "        \n",
    "# assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / VAL_LENGTH, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * NUM_DISPLAY))\n",
    "rows, columns = NUM_DISPLAY, 2\n",
    "for i in range(NUM_DISPLAY):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(preds[i])\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig(path.join(image_path, 'validation_{}.pdf'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ground_truths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_unet",
   "language": "python",
   "name": "venv_unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
