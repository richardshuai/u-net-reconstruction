{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from CLR.clr_callback import CyclicLR\n",
    "\n",
    "import io\n",
    "import json\n",
    "from os import path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = 'model-5.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "record_dir = path.join('..', 'data', model_description)\n",
    "dataset_files = glob.glob(path.join(record_dir, '*'))\n",
    "\n",
    "\n",
    "# Paths for saving/loading model weights, predictions\n",
    "base_path = path.join('..', 'trained_models', model_description)\n",
    "model_weights_path = path.join(base_path, model_description)\n",
    "image_path = path.join(base_path, 'prediction-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(base_path)\n",
    "os.mkdir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LENGTH = len(dataset_files)\n",
    "input_shape = (DATASET_LENGTH, 648, 486, 1)\n",
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batchnorm epsilon\n",
    "BN_EPS = 1e-4\n",
    "\n",
    "# Use float16\n",
    "# tf.keras.backend.set_floatx('float16')\n",
    "\n",
    "class ConvBnRelu2d(layers.Layer):\n",
    "    # Convolutional -> Batch norm -> ReLU\n",
    "    \n",
    "    def __init__(self, out_channels, kernel_size=(3, 3), padding='same', dilation_rate=1):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        self.conv = layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', \n",
    "                                  dilation_rate=dilation_rate, use_bias=False)\n",
    "        self.bn = layers.BatchNormalization(epsilon=BN_EPS)\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class StackEncoder(layers.Layer):\n",
    "    # ConvBnRelu -> ConvBnRelu -> * -> max pool (2x2)\n",
    "    #      * store tensor for concatenation with expansive path\n",
    "\n",
    "    def __init__(self, y_channels, kernel_size=3, dilation_rate=1):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        self.encode = keras.Sequential([\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate)\n",
    "        ])\n",
    "        \n",
    "        self.max_pool = layers.MaxPool2D(pool_size=2, strides=2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encode(x)\n",
    "        x_small = self.max_pool(x)\n",
    "        return x, x_small\n",
    "\n",
    "\n",
    "class StackDecoder(layers.Layer):\n",
    "    # Upsample (2x) -> concatenation -> ConvBnRelu -> ConvBnRelu -> ConvBnRelu\n",
    "\n",
    "    def __init__(self, y_channels, kernel_size=3, dilation_rate=1):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        self.decode = keras.Sequential([\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def call(self, x, down_tensor):\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        \n",
    "        # Calculate cropping for down_tensor to concatenate with x\n",
    "        _, h2, w2, _ = down_tensor.shape\n",
    "        _, h1, w1, _ = x.shape\n",
    "        h_diff, w_diff = h2 - h1, w2 - w1\n",
    "        \n",
    "        cropping = ((int(np.ceil(h_diff / 2)), int(np.floor(h_diff / 2))),\n",
    "                    (int(np.ceil(w_diff / 2)), int(np.floor(w_diff / 2))))\n",
    "        down_tensor = layers.Cropping2D(cropping=cropping)(down_tensor)        \n",
    "        x = layers.concatenate([x, down_tensor], axis=3)\n",
    "        x = self.decode(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_2d(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(UNet_2d, self).__init__()\n",
    "        self.down1 = StackEncoder(24, kernel_size=3, dilation_rate=4)\n",
    "        self.down2 = StackEncoder(64, kernel_size=3, dilation_rate=4)\n",
    "        self.down3 = StackEncoder(128, kernel_size=3, dilation_rate=4)\n",
    "        self.down4 = StackEncoder(256, kernel_size=3, dilation_rate=4)\n",
    "        self.down5 = StackEncoder(512, kernel_size=3, dilation_rate=4)\n",
    "        self.down6 = StackEncoder(1024, kernel_size=3, dilation_rate=4)\n",
    "\n",
    "        self.up6 = StackDecoder(512, kernel_size=3, dilation_rate=4)\n",
    "        self.up5 = StackDecoder(256, kernel_size=3, dilation_rate=4)\n",
    "        self.up4 = StackDecoder(128, kernel_size=3, dilation_rate=4)\n",
    "        self.up3 = StackDecoder(64, kernel_size=3, dilation_rate=4)\n",
    "        self.up2 = StackDecoder(24, kernel_size=3, dilation_rate=4)\n",
    "        self.up1 = StackDecoder(24, kernel_size=3, dilation_rate=4)\n",
    "        \n",
    "        # Final prediction uses a single feature channel (green)\n",
    "        self.classify = layers.Conv2D(filters=1, kernel_size=1, use_bias=True)\n",
    "        \n",
    "#         self.center = ConvBnRelu2d(512, kernel_size=3, padding='same')\n",
    "        self.center = ConvBnRelu2d(1024, kernel_size=3, padding='same')\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        out = x;\n",
    "        down1_tensor, out = self.down1(out)\n",
    "        down2_tensor, out = self.down2(out)\n",
    "        down3_tensor, out = self.down3(out)\n",
    "        down4_tensor, out = self.down4(out)\n",
    "        down5_tensor, out = self.down5(out)\n",
    "        down6_tensor, out = self.down6(out)\n",
    "\n",
    "        out = self.center(out)\n",
    "\n",
    "        out = self.up6(out, down6_tensor)\n",
    "        out = self.up5(out, down5_tensor)\n",
    "        out = self.up4(out, down4_tensor)\n",
    "        out = self.up3(out, down3_tensor)\n",
    "        out = self.up2(out, down2_tensor)\n",
    "        out = self.up1(out, down1_tensor)\n",
    "\n",
    "        out = self.classify(out)\n",
    "        out = tf.squeeze(out, axis=3)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        'plane': tf.io.FixedLenFeature(obj_dims, tf.float32),\n",
    "        'sim': tf.io.FixedLenFeature(obj_dims, tf.float32)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    \n",
    "    plane = example['plane']\n",
    "#     plane = tf.cast(plane, tf.float16)\n",
    "#     plane = plane[4:644, 3:483] # Crop to target image size\n",
    "    plane = plane[4:644, 19:467]\n",
    "    plane_max = tf.reduce_max(plane)\n",
    "    plane_min = tf.reduce_min(plane)\n",
    "    plane = (plane - plane_min) / (plane_max - plane_min)  # Normalize values to [0, 1]\n",
    "\n",
    "    sim = example['sim']\n",
    "#     sim = tf.cast(sim, tf.float16)\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)  # Normalize values to [0, 1]\n",
    "    \n",
    "    # Adding noise to simulated measurements\n",
    "    a = np.random.uniform(0.0063, 0.0063*4)\n",
    "    b = np.random.uniform(0.06, 0.1)\n",
    "    noise = a*np.random.randn(*sim.shape) + b\n",
    "    sim = sim + noise\n",
    "\n",
    "    # Renormalize values to [0, 1]\n",
    "    sim_max = tf.reduce_max(sim)\n",
    "    sim_min = tf.reduce_min(sim)\n",
    "    sim = (sim - sim_min) / (sim_max - sim_min)\n",
    "    \n",
    "    # Expand to channel dimension\n",
    "    sim = sim[..., np.newaxis] \n",
    "    \n",
    "    return sim, plane\n",
    "\n",
    "def create_datasets(filenames, train_length, val_length, batch_size):\n",
    "    \"\"\"\n",
    "    Takes in string array of filenames for TFRecord files containing samples.\n",
    "    Returns: train dataset of train_length, val dataset of val_length\n",
    "    \"\"\"\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "\n",
    "    raw_train_dataset = tf.data.TFRecordDataset(filenames[:train_length])\n",
    "    raw_val_dataset = tf.data.TFRecordDataset(filenames[train_length:train_length + val_length])\n",
    "\n",
    "    train_dataset = raw_train_dataset.map(_parse_function)\n",
    "    train_dataset = train_dataset.shuffle(256)\n",
    "    train_dataset = train_dataset.repeat()\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "\n",
    "    val_dataset = raw_val_dataset.map(_parse_function)\n",
    "    val_dataset = val_dataset.shuffle(256)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = 5000\n",
    "VAL_LENGTH = 1000\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "VAL_STEPS = VAL_LENGTH // BATCH_SIZE\n",
    "\n",
    "SAMPLES_PER_EPOCH = BATCH_SIZE*STEPS_PER_EPOCH\n",
    "\n",
    "CLR_STEPS = STEPS_PER_EPOCH * 8\n",
    "\n",
    "train_dataset, val_dataset = create_datasets(filenames=dataset_files, train_length=TRAIN_LENGTH, \n",
    "                                  val_length=VAL_LENGTH, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "\n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def scaled_mse_loss(y_actual,y_pred):\n",
    "    loss = K.square((y_actual-y_pred))\n",
    "#     loss = K.sqrt(loss)\n",
    "    loss = K.sum(loss)\n",
    "    return loss\n",
    "\n",
    "def plot_image_tensorboard(epoch, logs):\n",
    "    # Create a plot to visualize image reconstruction progress\n",
    "    \n",
    "    # Call the model to get prediction\n",
    "    pred = model.predict(val_sample[0][0][np.newaxis])\n",
    "\n",
    "    # Create a mpl figure\n",
    "    figure = plt.figure(figsize=(10,10))\n",
    "\n",
    "    # Plot the prediction\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(pred[0].astype(np.float32))\n",
    "    # Plot groundtruth\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"ground truth\")\n",
    "    plt.imshow(val_sample[1][0].numpy().astype(np.float32))\n",
    "    plot_image = plot_to_image(figure)\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Prediction vs Ground Truth\", plot_image, step=epoch)\n",
    "\n",
    "import datetime\n",
    "log_dir=os.path.join('logs', model_description + '-fit') + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=1000000)\n",
    "file_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "plot_image_tensorboard_cb = keras.callbacks.LambdaCallback(on_epoch_end=plot_image_tensorboard)\n",
    "\n",
    "# Save model after epochs\n",
    "checkpoint_cb = ModelCheckpoint(model_weights_path + '.e{epoch:03d}', monitor='val_loss', verbose=0, \n",
    "                             save_best_only=False, save_weights_only=True, mode='auto', \n",
    "                                save_freq=10*STEPS_PER_EPOCH)\n",
    "checkpoint_best_cb = ModelCheckpoint(model_weights_path + '.best', monitor='val_loss', verbose=0,\n",
    "                                    save_best_only=True, save_weights_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_2d()\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "# model.compile(optimizer=adam, loss=tf.keras.losses.MeanAbsoluteError(), metrics=[tf.keras.losses.MeanAbsoluteError()])\n",
    "model.build(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sample = next(iter(val_dataset)) # Used for logging and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clr = CyclicLR(base_lr=1e-4, max_lr=5e-4,\n",
    "#                         step_size=CLR_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "#           callbacks=[plot_image_tensorboard_cb, tensorboard_callback, checkpoint_cb, checkpoint_best_cb, clr], \n",
    "#           validation_data=val_dataset, validation_steps=VAL_STEPS)\n",
    "model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "          callbacks=[plot_image_tensorboard_cb, tensorboard_callback, checkpoint_cb, checkpoint_best_cb], \n",
    "          validation_data=val_dataset, validation_steps=VAL_STEPS)\n",
    "\n",
    "model.save_weights(model_weights_path, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Visualization, Timing Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DISPLAY = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_2d()\n",
    "model.load_weights(model_weights_path + '.e450')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((NUM_DISPLAY, 640, 448))\n",
    "ground_truths = np.zeros((NUM_DISPLAY, 640, 448))\n",
    "sims = np.zeros((NUM_DISPLAY, 648, 486))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in train_dataset.unbatch():\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "    if i == NUM_DISPLAY:\n",
    "        break\n",
    "        \n",
    "# assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / VAL_LENGTH, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * NUM_DISPLAY))\n",
    "rows, columns = NUM_DISPLAY, 2\n",
    "for i in range(NUM_DISPLAY):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(preds[i])\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig(path.join(image_path, 'train.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.perf_counter()\n",
    "i = 0\n",
    "for sim, plane in val_dataset.unbatch():\n",
    "    preds[i] = model.predict(sim[np.newaxis])\n",
    "    ground_truths[i] = plane\n",
    "    sims[i] = np.squeeze(sim)\n",
    "    i += 1\n",
    "    if i == NUM_DISPLAY:\n",
    "        break\n",
    "        \n",
    "# assert(i == VAL_LENGTH)\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print('Prediction time per sample:', (t1 - t0) / VAL_LENGTH, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(30, 15 * NUM_DISPLAY))\n",
    "rows, columns = NUM_DISPLAY, 2\n",
    "for i in range(NUM_DISPLAY):\n",
    "    # Plot prediction\n",
    "    s = fig.add_subplot(rows, columns, columns*i+1)\n",
    "    s.set_title(\"prediction {0}\".format(i), size=20)\n",
    "    plt.imshow(preds[i])\n",
    "    \n",
    "    # Plot ground truth\n",
    "    s = fig.add_subplot(rows, columns, columns*i+2)\n",
    "    s.set_title(\"ground truth {0}\".format(i), size=20)\n",
    "    plt.imshow(ground_truths[i])\n",
    "    \n",
    "plt.savefig(path.join(image_path, 'validation.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ground_truths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
