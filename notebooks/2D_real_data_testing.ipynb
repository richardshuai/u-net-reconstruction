{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dims = (648, 486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import json\n",
    "import scipy.io as sio\n",
    "from os import path\n",
    "\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_description = 'model-5.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_path = path.join('..', 'data', 'real-data', 'realData.mat')\n",
    "ground_truth_path = path.join('..', 'data', 'real-data', 'beads_GT.png')\n",
    "\n",
    "# Paths for saving/loading model weights, predictions\n",
    "base_path = path.join('..', 'models', model_description)\n",
    "model_weights_path = path.join(base_path, model_description)\n",
    "image_path = path.join(base_path, 'prediction-images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batchnorm epsilon\n",
    "BN_EPS = 1e-4\n",
    "\n",
    "# Use float16\n",
    "# tf.keras.backend.set_floatx('float16')\n",
    "\n",
    "class ConvBnRelu2d(layers.Layer):\n",
    "    # Convolutional -> Batch norm -> ReLU\n",
    "    \n",
    "    def __init__(self, out_channels, kernel_size=(3, 3), padding='same', dilation_rate=1):\n",
    "        super(ConvBnRelu2d, self).__init__()\n",
    "        self.conv = layers.Conv2D(filters=out_channels, kernel_size=kernel_size, padding='same', \n",
    "                                  dilation_rate=dilation_rate, use_bias=False)\n",
    "        self.bn = layers.BatchNormalization(epsilon=BN_EPS)\n",
    "        self.relu = layers.ReLU()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class StackEncoder(layers.Layer):\n",
    "    # ConvBnRelu -> ConvBnRelu -> * -> max pool (2x2)\n",
    "    #      * store tensor for concatenation with expansive path\n",
    "\n",
    "    def __init__(self, y_channels, kernel_size=3, dilation_rate=1):\n",
    "        super(StackEncoder, self).__init__()\n",
    "        self.encode = keras.Sequential([\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate)\n",
    "        ])\n",
    "        \n",
    "        self.max_pool = layers.MaxPool2D(pool_size=2, strides=2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encode(x)\n",
    "        x_small = self.max_pool(x)\n",
    "        return x, x_small\n",
    "\n",
    "\n",
    "class StackDecoder(layers.Layer):\n",
    "    # Upsample (2x) -> concatenation -> ConvBnRelu -> ConvBnRelu -> ConvBnRelu\n",
    "\n",
    "    def __init__(self, y_channels, kernel_size=3, dilation_rate=1):\n",
    "        super(StackDecoder, self).__init__()\n",
    "        self.decode = keras.Sequential([\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ConvBnRelu2d(y_channels, kernel_size=kernel_size, padding='same', dilation_rate=dilation_rate),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def call(self, x, down_tensor):\n",
    "        x = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "        \n",
    "        # Calculate cropping for down_tensor to concatenate with x\n",
    "        _, h2, w2, _ = down_tensor.shape\n",
    "        _, h1, w1, _ = x.shape\n",
    "        h_diff, w_diff = h2 - h1, w2 - w1\n",
    "        \n",
    "        cropping = ((int(np.ceil(h_diff / 2)), int(np.floor(h_diff / 2))),\n",
    "                    (int(np.ceil(w_diff / 2)), int(np.floor(w_diff / 2))))\n",
    "        down_tensor = layers.Cropping2D(cropping=cropping)(down_tensor)        \n",
    "        x = layers.concatenate([x, down_tensor], axis=3)\n",
    "        x = self.decode(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_2d(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(UNet_2d, self).__init__()\n",
    "        self.down1 = StackEncoder(24, kernel_size=3, dilation_rate=4)\n",
    "        self.down2 = StackEncoder(64, kernel_size=3, dilation_rate=4)\n",
    "        self.down3 = StackEncoder(128, kernel_size=3, dilation_rate=4)\n",
    "        self.down4 = StackEncoder(256, kernel_size=3, dilation_rate=4)\n",
    "        self.down5 = StackEncoder(512, kernel_size=3, dilation_rate=4)\n",
    "        self.down6 = StackEncoder(1024, kernel_size=3, dilation_rate=4)\n",
    "\n",
    "        self.up6 = StackDecoder(512, kernel_size=3, dilation_rate=4)\n",
    "        self.up5 = StackDecoder(256, kernel_size=3, dilation_rate=4)\n",
    "        self.up4 = StackDecoder(128, kernel_size=3, dilation_rate=4)\n",
    "        self.up3 = StackDecoder(64, kernel_size=3, dilation_rate=4)\n",
    "        self.up2 = StackDecoder(24, kernel_size=3, dilation_rate=4)\n",
    "        self.up1 = StackDecoder(24, kernel_size=3, dilation_rate=4)\n",
    "        \n",
    "        # Final prediction uses a single feature channel (green)\n",
    "        self.classify = layers.Conv2D(filters=1, kernel_size=1, use_bias=True)\n",
    "        \n",
    "#         self.center = ConvBnRelu2d(512, kernel_size=3, padding='same')\n",
    "        self.center = ConvBnRelu2d(1024, kernel_size=3, padding='same')\n",
    "        \n",
    "        \n",
    "    def call(self, x):\n",
    "        out = x;\n",
    "        down1_tensor, out = self.down1(out)\n",
    "        down2_tensor, out = self.down2(out)\n",
    "        down3_tensor, out = self.down3(out)\n",
    "        down4_tensor, out = self.down4(out)\n",
    "        down5_tensor, out = self.down5(out)\n",
    "        down6_tensor, out = self.down6(out)\n",
    "\n",
    "        out = self.center(out)\n",
    "\n",
    "        out = self.up6(out, down6_tensor)\n",
    "        out = self.up5(out, down5_tensor)\n",
    "        out = self.up4(out, down4_tensor)\n",
    "        out = self.up3(out, down3_tensor)\n",
    "        out = self.up2(out, down2_tensor)\n",
    "        out = self.up1(out, down1_tensor)\n",
    "\n",
    "        out = self.classify(out)\n",
    "        out = tf.squeeze(out, axis=3)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_2d()\n",
    "model.load_weights(model_weights_path + '.e400')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in older mat files with scipy.io\n",
    "data = sio.loadmat(real_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beads, res = data['beads'], data['resTarget']\n",
    "beads = np.array(Image.fromarray(beads).resize(obj_dims, resample=PIL.Image.NEAREST))\n",
    "b_min = np.min(beads)\n",
    "b_max = np.max(beads)\n",
    "beads_input_normed = ((beads - b_min) / (b_max - b_min)).T\n",
    "beads_input = beads_input_normed.astype(np.float16)[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array(Image.fromarray(res).resize(obj_dims, resample=PIL.Image.NEAREST))\n",
    "r_min = np.min(res)\n",
    "r_max = np.max(res)\n",
    "res_input_normed = ((res - r_min) / (r_max - r_min)).T\n",
    "res_input = res_input_normed.astype(np.float16)[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_beads = model.predict(beads_input).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = model.predict(res_input).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beads_gt_im = Image.open(ground_truth_path)\n",
    "beads_gt = np.array(beads_gt_im).T\n",
    "# Normalize beads from 0 to 1\n",
    "beads_gt = (beads_gt - np.min(beads_gt)) / (np.max(beads_gt) - np.min(beads_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 30))\n",
    "f0 = fig.add_subplot(1, 3, 1)\n",
    "f0.set_title('beads ground truth')\n",
    "f0.imshow(beads_gt)\n",
    "\n",
    "f1 = fig.add_subplot(1, 3, 2)\n",
    "f1.set_title('my beads reconstruction') # Normalized before simulation, but not after\n",
    "f1.imshow(pred_beads)\n",
    "\n",
    "f2 = fig.add_subplot(1, 3, 3)\n",
    "f2.set_title('input')\n",
    "f2.imshow(beads_input_normed)\n",
    "\n",
    "\n",
    "plt.savefig(path.join(image_path, 'beads_reconstruction.pdf'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 30))\n",
    "f1 = fig.add_subplot(1, 3, 2)\n",
    "f1.set_title('my res reconstruction') # Normalized before simulation, but not after\n",
    "f1.imshow(pred_res)\n",
    "\n",
    "f2 = fig.add_subplot(1, 3, 3)\n",
    "f2.set_title('res input')\n",
    "f2.imshow(res_input_normed)\n",
    "\n",
    "plt.savefig(path.join(image_path, 'res_reconstruction.pdf'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(pred_beads), np.min(pred_beads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(beads_gt), np.min(beads_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(pred_res), np.min(pred_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(res_input_normed), np.min(res_input_normed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
